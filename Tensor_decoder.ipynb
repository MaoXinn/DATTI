{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _*_ coding:utf-8 _*_\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tqdm import tqdm\n",
    "from scipy import optimize\n",
    "from evaluate import evaluate\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from utils import *\n",
    "import tensorly\n",
    "import json\n",
    "import os\n",
    "\n",
    "seed = 12306\n",
    "np.random.seed(seed)\n",
    "\n",
    "#choose the GPU, \"-1\" represents using the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tensorly.set_backend('tensorflow')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type=\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)\n",
    "\n",
    "#choose the base model and dataset\n",
    "model = [\"Dual_AMN\",\"TransEdge\",\"RSN\"][0]\n",
    "dataset = [\"DBP_ZH_EN/\",\"DBP_JA_EN/\",\"DBP_FR_EN/\",\"SRPRS_FR_EN/\",\"SRPRS_DE_EN/\"][0]\n",
    "\n",
    "if \"DBP\" in dataset:\n",
    "    path = \"./EA_datasets/\"+ (\"sharing/\" if model == \"TransEdge\" else \"mapping/\") + dataset + \"0_3/\"\n",
    "else:\n",
    "    path = \"./EA_datasets/\"+ (\"sharing/\" if model == \"TransEdge\" else \"mapping/\") + dataset\n",
    "    \n",
    "train_pair,test_pair = load_aligned_pair(path,ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 10:50:38.975285: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 10:50:39.433999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22320 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#build the adjacency sparse tensor of KGs and load the initial embeddings\n",
    "triples = []\n",
    "\n",
    "flag = model == \"Dual_AMN\"\n",
    "with open(path + \"triples_1\") as f:\n",
    "    for line in f.readlines():\n",
    "        h,r,t = [int(x) for x in line.strip().split(\"\\t\")]\n",
    "        triples.append([h,t,r+flag])\n",
    "with open(path + \"triples_2\") as f:\n",
    "    for line in f.readlines():\n",
    "        h,r,t = [int(x) for x in line.strip().split(\"\\t\")]\n",
    "        triples.append([h,t,r+flag])\n",
    "\n",
    "if model != \"TransEdge\":\n",
    "    triples = np.array(triples)\n",
    "    triples = np.unique(triples,axis=0)\n",
    "    node_size,rel_size = np.max(triples[:,0])+1 , np.max(triples[:,2])+1\n",
    "    triples = np.concatenate([triples,[(t,h,r+rel_size) for h,t,r in triples]],axis=0)\n",
    "    rel_size = rel_size * 2\n",
    "    \n",
    "    if model == \"RSN\":\n",
    "        emb_path = \"Embeddings/RSN/%s\"%dataset\n",
    "        ent_emb = tf.cast(np.load(emb_path + \"ent_emb.npy\"),\"float32\")\n",
    "        rel_emb = tf.cast(np.load(emb_path + \"rel_emb.npy\"),\"float32\")\n",
    "        ent_dic,rel_dic = json.load(open(emb_path+\"ent_id2id.json\")),json.load(open(emb_path+\"rel_id2id.json\"))\n",
    "        new_triples,new_test = [],[]\n",
    "        for h,t,r in triples:\n",
    "            new_triples.append([int(ent_dic[str(h)]),int(ent_dic[str(t)]),int(rel_dic[str(r)])])\n",
    "        for a,b in test_pair:\n",
    "            new_test.append([int(ent_dic[str(a)]),int(ent_dic[str(b)])])\n",
    "        triples = np.array(new_triples)\n",
    "        test_pair = np.array(new_test)\n",
    "    else:\n",
    "        triples = np.concatenate([triples,[(t,t,0) for t in range(node_size)]],axis=0)\n",
    "        ent_emb = tf.cast(np.load(\"Embeddings/Dual_AMN/%sent_emb.npy\"%dataset),\"float32\")\n",
    "        rel_emb = tf.cast(np.load(\"Embeddings/Dual_AMN/%srel_emb.npy\"%dataset),\"float32\")\n",
    "        \n",
    "    triples = np.unique(triples,axis=0)\n",
    "    \n",
    "else:\n",
    "    triples = np.array(triples)\n",
    "    triples = np.unique(triples,axis=0)\n",
    "    node_size,rel_size = np.max(triples)+1 , np.max(triples[:,2])+1\n",
    "    triples = np.concatenate([triples,[(t,h,r) for h,t,r in triples]],axis=0)\n",
    "    triples = np.unique(triples,axis=0)\n",
    "    ent_emb = tf.cast(np.load(\"Embeddings/TransEdge/%sent_embeds.npy\"%dataset),\"float32\")\n",
    "    rel_emb = tf.cast(np.load(\"Embeddings/TransEdge/%srel_embeds.npy\"%dataset),\"float32\")\n",
    "\n",
    "\n",
    "ent_ent,triples_idx = [],[]\n",
    "pair_dict,ent_degree = {},{}\n",
    "last,index = (-1,-1), -1\n",
    "\n",
    "for h,t,r in triples:\n",
    "    if h not in ent_degree:\n",
    "        ent_degree[h] = 0\n",
    "    ent_degree[h] += 1\n",
    "    \n",
    "    if (h,t) != last:\n",
    "        last = (h,t)\n",
    "        index += 1\n",
    "        ent_ent.append([h,t])\n",
    "    \n",
    "    triples_idx.append([index,r])\n",
    "ent_ent = np.array(ent_ent)\n",
    "triples_idx = np.unique(np.array(triples_idx),axis=0)\n",
    "triples_val = np.array([1/ent_degree[ent_ent[idx][0]] for idx,_ in triples_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 10:50:43.309175: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|████████████████████████████████████████| 128/128 [00:00<00:00, 195.18it/s]\n",
      "2021-11-16 10:50:43.969572: I tensorflow/core/util/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x5642e7253df0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38960, 1920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@1 : 83.50% hits@10 : 95.14% MRR : 87.96%\n",
      "CPU times: user 3.22 s, sys: 767 ms, total: 3.99 s\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute H^l_s and H^l_t and slove the assignment problem by Sinkhorn operator\n",
    "def random_projection(x,out_dim):\n",
    "    random_vec = K.l2_normalize(tf.random.normal((x.shape[-1],out_dim),mean=0,stddev=(1/out_dim)**0.5),axis=-1)\n",
    "    return K.dot(x,random_vec)\n",
    "\n",
    "def cal_sims(test_pair,feature):\n",
    "    feature = tf.nn.l2_normalize(feature,axis = -1)\n",
    "    feature_a = tf.gather(indices=test_pair[:,0],params=feature)\n",
    "    feature_b = tf.gather(indices=test_pair[:,1],params=feature)\n",
    "    return tf.matmul(feature_a,tf.transpose(feature_b,[1,0]))\n",
    "\n",
    "sims = cal_sims(test_pair,ent_emb)\n",
    "\n",
    "reserve_ratio = 0.02\n",
    "ent_size,rel_size = ent_emb.shape[-1],rel_emb.shape[-1]\n",
    "total_feature_size = int(ent_size*reserve_ratio)*rel_size\n",
    "\n",
    "features = []\n",
    "for head in tqdm(range(rel_size)):\n",
    "    rel_weight = tf.gather(rel_emb[:,head],triples_idx[:,1])\n",
    "    adj_value = tf.math.segment_sum(triples_val * rel_weight, triples_idx[:,0])\n",
    "    sparse_graph = tf.SparseTensor(indices=ent_ent,values=adj_value,dense_shape=(ent_emb.shape[0],ent_emb.shape[0]))\n",
    "    feature = tf.sparse.sparse_dense_matmul(sparse_graph,ent_emb)\n",
    "    features.append(random_projection(feature,int(ent_size*reserve_ratio)))\n",
    "features = tf.concat(features,axis=1)\n",
    "print(features.shape)\n",
    "features = tensorly.truncated_svd(features,total_feature_size)[0]\n",
    "sims += cal_sims(test_pair,features)\n",
    "\n",
    "depth = 3\n",
    "for i in tqdm(range(depth)):\n",
    "    sparse_graph = tf.SparseTensor(indices=ent_ent,values=tf.ones(ent_ent.shape[0]),dense_shape=(ent_emb.shape[0],ent_emb.shape[0]))\n",
    "    sparse_graph = tf.sparse.softmax(sparse_graph)\n",
    "    features = tf.sparse.sparse_dense_matmul(sparse_graph,features)\n",
    "    sims += cal_sims(test_pair,features)\n",
    "\n",
    "sims /= 2+depth\n",
    "sims = tf.exp(sims/0.02)\n",
    "for k in range(15):\n",
    "    sims = sims / tf.reduce_sum(sims,axis=1,keepdims=True)\n",
    "    sims = sims / tf.reduce_sum(sims,axis=0,keepdims=True)\n",
    "test(sims,\"sinkhorn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 10:50:46.907276: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1:  0.8039047619047619   Hits@5:  0.9155238095238095   Hits@10:  0.9368571428571428   MRR:  0.8529688830473474\n"
     ]
    }
   ],
   "source": [
    "# the results of base model\n",
    "def csls_sims(test_pair,feature):\n",
    "    evaluater = evaluate(test_pair)\n",
    "    feature = tf.nn.l2_normalize(feature,axis = -1)\n",
    "    feature_a = tf.gather(indices=test_pair[:,0],params=feature)\n",
    "    feature_b = tf.gather(indices=test_pair[:,1],params=feature)\n",
    "    evaluater.test(feature_a,feature_b)\n",
    "\n",
    "csls_sims(test_pair,ent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@1 : 79.95%\n"
     ]
    }
   ],
   "source": [
    "# the results of the Hungarian algorithm\n",
    "sims = cal_sims(test_pair,ent_emb)\n",
    "result = optimize.linear_sum_assignment(sims,maximize=True)\n",
    "test(result,\"hungarian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.6",
   "language": "python",
   "name": "tf2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
